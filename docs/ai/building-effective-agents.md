# 构建有效的代理

在过去的一年里，我们与数十个团队合作，跨行业构建大型语言模型（LLM）代理。一致的是，最成功的实施并没有使用复杂的框架或专门的库。相反，他们使用的是简单、可组合的模式。

在这篇文章中，我们分享了从与客户合作和自行构建代理中学到的经验，并为开发者提供了构建有效代理的实用建议。

**什么是代理？**
“代理”可以有多种定义。一些客户将代理定义为完全自主的系统，能够长时间独立运行，使用各种工具完成复杂任务。其他人则用这个术语来描述遵循预定义工作流程的更具规定性的实施。在 Anthropic，我们将所有这些变体归类为代理系统，但在工作流程和代理之间划出了重要的架构区别：

- **工作流程**是通过预定义代码路径编排 LLMs 和工具的系统。
- **代理**则是 LLMs 动态指导自己的流程和工具使用，保持对任务完成方式的控制的系统。

下面，我们将详细探讨这两种代理系统。在附录 1（“实践中的代理”）中，我们描述了客户在使用这些系统时发现特别有价值的两个领域。

**何时（以及何时不）使用代理**
在使用 LLMs 构建应用程序时，我们建议找到最简单的解决方案，只有在需要时才增加复杂性。这可能意味着根本不构建代理系统。代理系统通常以延迟和成本为代价换取更好的任务性能，您应该考虑何时这种权衡是合理的。

当需要更多复杂性时，工作流程为定义明确的任务提供了可预测性和一致性，而代理则是在需要灵活性和模型驱动的决策时更好的选择。然而，对于许多应用程序来说，通过检索和上下文示例优化单个 LLM 调用通常就足够了。

**何时以及如何使用框架**
有许多框架可以使代理系统更容易实现，包括：

- LangChain 的 LangGraph；
- Amazon Bedrock 的 AI 代理框架；
- Rivet，一个拖放式 GUI LLM 工作流程构建器；以及
- Vellum，另一个用于构建和测试复杂工作流程的 GUI 工具。

这些框架通过简化标准的低级任务（如调用 LLMs、定义和解析工具以及链接调用）使入门变得容易。然而，它们通常会创建额外的抽象层，可能会掩盖底层的提示和响应，使其更难调试。它们还可能诱使您在更简单的设置就足够时增加复杂性。

我们建议开发者首先直接使用 LLM API：许多模式可以用几行代码实现。如果您确实使用框架，请确保您了解底层代码。对底层内容的错误假设是客户错误的常见来源。

请参阅我们的食谱以获取一些示例实现。

**构建模块、工作流程和代理**
在本节中，我们将探讨我们在生产中看到的代理系统的常见模式。我们将从我们的基础构建模块——增强型 LLM——开始，逐步增加复杂性，从简单的组合工作流程到自主代理。

**构建模块：增强型 LLM**
代理系统的基本构建模块是通过检索、工具和记忆等增强功能增强的 LLM。我们当前的模型可以主动使用这些功能——生成自己的搜索查询、选择适当的工具并确定保留哪些信息。

我们建议关注实施的两个关键方面：根据您的具体用例定制这些功能，并确保它们为您的 LLM 提供易于使用的、文档完善的接口。虽然有许多方法可以实现这些增强功能，但一种方法是通过我们最近发布的模型上下文协议，该协议允许开发者通过简单的客户端实现与不断增长的第三方工具生态系统集成。

在本文的其余部分，我们将假设每个 LLM 调用都可以访问这些增强功能。

**工作流程：提示链**
提示链将任务分解为一系列步骤，其中每个 LLM 调用处理前一个调用的输出。您可以在任何中间步骤上添加程序检查（见下图中的“门”），以确保过程仍在正轨上。

**何时使用此工作流程**：此工作流程非常适合可以轻松且干净地分解为固定子任务的任务。主要目标是通过使每个 LLM 调用成为更简单的任务来以延迟换取更高的准确性。

**提示链有用的示例**：

- 生成营销文案，然后将其翻译成不同的语言。
- 编写文档大纲，检查大纲是否符合某些标准，然后根据大纲编写文档。

**工作流程：路由**
路由对输入进行分类并将其定向到专门的后续任务。此工作流程允许关注点分离，并构建更专业的提示。如果没有此工作流程，优化一种输入可能会损害其他输入的性能。

**何时使用此工作流程**：路由适用于复杂任务，其中存在更好单独处理的不同类别，并且分类可以通过 LLM 或更传统的分类模型/算法准确处理。

**路由有用的示例**：

- 将不同类型的客户服务查询（一般问题、退款请求、技术支持）定向到不同的下游流程、提示和工具。
- 将简单/常见问题路由到较小的模型（如 Claude 3.5 Haiku），将困难/不常见的问题路由到更强大的模型（如 Claude 3.5 Sonnet）以优化成本和速度。

**工作流程：并行化**
LLMs 有时可以同时处理任务，并通过程序聚合它们的输出。此工作流程，并行化，表现为两个关键变体：

- **分段**：将任务分解为并行运行的独立子任务。
- **投票**：多次运行同一任务以获得多样化的输出。

**何时使用此工作流程**：当划分的子任务可以并行化以提高速度，或者当需要多个视角或尝试以获得更高置信度的结果时，并行化是有效的。对于具有多个考虑的复杂任务，LLMs 通常在每个考虑由单独的 LLM 调用处理时表现更好，从而允许对每个特定方面进行集中关注。

**并行化有用的示例**：

- **分段**：
  - 实施护栏，其中一个模型实例处理用户查询，而另一个模型实例筛选它们以查找不适当的内容或请求。这往往比让同一个 LLM 调用同时处理护栏和核心响应表现更好。
  - 自动化评估 LLM 性能的评估，其中每个 LLM 调用评估模型在给定提示下的不同方面的性能。
- **投票**：
  - 审查一段代码的漏洞，其中几个不同的提示审查并标记代码，如果发现问题。
  - 评估给定内容是否不适当，多个提示评估不同方面或需要不同的投票阈值以平衡误报和漏报。

**工作流程：协调者-工作者**
在协调者-工作者工作流程中，一个中央 LLM 动态分解任务，将它们委派给工作者 LLMs，并综合它们的结果。

**何时使用此工作流程**：此工作流程非常适合复杂任务，其中您无法预测所需的子任务（例如，在编码中，需要更改的文件数量和每个文件中的更改性质可能取决于任务）。虽然它在拓扑上相似，但与并行化的关键区别在于其灵活性——子任务不是预定义的，而是由协调者根据特定输入确定的。

**协调者-工作者有用的示例**：

- 每次对多个文件进行复杂更改的编码产品。
- 涉及从多个来源收集和分析信息以获取可能相关信息的搜索任务。

**工作流程：评估者-优化器**
在评估者-优化器工作流程中，一个 LLM 调用生成响应，而另一个 LLM 在循环中提供评估和反馈。

**何时使用此工作流程**：当我们有明确的评估标准，并且迭代改进提供了可衡量的价值时，此工作流程特别有效。两个适合的标志是，首先，当人类表达他们的反馈时，LLM 响应可以明显改进；其次，LLM 可以提供这样的反馈。这类似于人类作家在生成精炼文档时可能经历的迭代写作过程。

**评估者-优化器有用的示例**：

- 文学翻译，其中翻译 LLM 可能最初没有捕捉到的细微差别，但评估者 LLM 可以提供有用的批评。
- 需要多轮搜索和分析以收集全面信息的复杂搜索任务，其中评估者决定是否需要进一步搜索。

**代理**
随着 LLMs 在关键能力上的成熟——理解复杂输入、参与推理和规划、可靠地使用工具以及从错误中恢复——代理正在生产中崭露头角。代理开始工作时，要么是来自人类用户的命令，要么是与人类用户的交互讨论。一旦任务明确，代理就会独立计划和操作，可能会返回给人类以获取更多信息或判断。在执行过程中，代理在每一步从环境中获取“真实情况”（如工具调用结果或代码执行）以评估其进展至关重要。代理可以在检查点或遇到障碍时暂停以获取人类反馈。任务通常在完成时终止，但通常也包括停止条件（如最大迭代次数）以保持控制。

代理可以处理复杂的任务，但它们的实施通常很简单。它们通常只是基于环境反馈循环使用工具的 LLMs。因此，清晰而周到地设计工具集及其文档至关重要。我们在附录 2（“提示工程您的工具”）中扩展了工具开发的最佳实践。

**何时使用代理**：代理可以用于开放式问题，其中难以或无法预测所需的步骤数量，并且您无法硬编码固定路径。LLM 可能会运行多次，您必须对其决策有一定程度的信任。代理的自主性使其成为在可信环境中扩展任务的理想选择。

代理的自主性意味着更高的成本和潜在的错误累积。我们建议在沙盒环境中进行广泛测试，并设置适当的护栏。

**代理有用的示例**：

以下示例来自我们自己的实施：

- 一个编码代理，用于解决 SWE-bench 任务，这些任务涉及基于任务描述对多个文件进行编辑；
- 我们的“计算机使用”参考实现，其中 Claude 使用计算机完成任务。

**编码代理的高级流程**
**组合和定制这些模式**
这些构建模块不是规定性的。它们是开发者可以塑造和组合以适应不同用例的常见模式。与任何 LLM 功能一样，成功的关键是衡量性能并迭代实施。再次强调：您应该仅在复杂性明显改善结果时才考虑增加复杂性。

**总结**
在 LLM 领域的成功不是构建最复杂的系统。而是构建适合您需求的系统。从简单的提示开始，通过全面评估优化它们，只有在更简单的解决方案不足时才添加多步代理系统。

在实施代理时，我们尝试遵循三个核心原则：

1. 保持代理设计的简单性。
2. 通过明确显示代理的规划步骤来优先考虑透明度。
3. 通过彻底的文档和测试精心设计代理-计算机接口（ACI）。

框架可以帮助您快速入门，但在进入生产时不要犹豫减少抽象层并使用基本组件构建。通过遵循这些原则，您可以创建不仅强大而且可靠、可维护并受用户信任的代理。

**致谢**
由 Erik Schluntz 和 Barry Zhang 撰写。这项工作借鉴了我们在 Anthropic 构建代理的经验以及客户分享的宝贵见解，我们对此深表感谢。

**附录 1：实践中的代理**
我们与客户的工作揭示了两个特别有前途的 AI 代理应用，展示了上述模式的实用价值。这两个应用都说明了代理在需要对话和操作、有明确成功标准、启用反馈循环并整合有意义的人类监督的任务中增加最大价值。

**A. 客户支持**
客户支持结合了熟悉的聊天机器人界面和通过工具集成增强的功能。这是更开放式代理的自然契合，因为：

- 支持交互自然地遵循对话流程，同时需要访问外部信息和操作；
- 可以集成工具以提取客户数据、订单历史记录和知识库文章；
- 诸如发放退款或更新票据等操作可以以编程方式处理；以及
- 可以通过用户定义的解决方案明确衡量成功。

几家公司通过基于使用情况的定价模型展示了这种方法的可行性，该模型仅对成功的解决方案收费，显示了对其代理有效性的信心。

**B. 编码代理**
软件开发领域展示了 LLM 功能的显著潜力，能力从代码完成发展到自主问题解决。代理特别有效，因为：

- 代码解决方案可以通过自动化测试验证；
- 代理可以使用测试结果作为反馈迭代解决方案；
- 问题空间定义明确且结构化；以及
- 输出质量可以客观衡量。

在我们自己的实施中，代理现在可以根据拉取请求描述单独解决 SWE-bench Verified 基准中的真实 GitHub 问题。然而，虽然自动化测试有助于验证功能，但人类审查对于确保解决方案符合更广泛的系统要求仍然至关重要。

**附录 2：提示工程您的工具**
无论您构建哪种代理系统，工具都可能是您代理的重要组成部分。工具使 Claude 能够通过在我们的 API 中指定其确切结构和定义与外部服务和 API 交互。当 Claude 响应时，如果它计划调用工具，它将在 API 响应中包含一个工具使用块。工具定义和规范应与您的整体提示一样受到提示工程的关注。在这个简短的附录中，我们描述了如何提示工程您的工具。

通常有几种方法可以指定相同的操作。例如，您可以通过编写差异或重写整个文件来指定文件编辑。对于结构化输出，您可以在 markdown 或 JSON 中返回代码。在软件工程中，这些差异是表面上的，可以无损地从一种转换为另一种。然而，某些格式比其他格式更难让 LLM 编写。编写差异需要知道在编写新代码之前块头中有多少行正在更改。在 JSON 中编写代码（与 markdown 相比）需要对换行符和引号进行额外的转义。

我们关于决定工具格式的建议如下：

- 给模型足够的令牌“思考”，以免它把自己逼入绝境。
- 保持格式接近模型在互联网文本中自然看到的内容。
- 确保没有格式“开销”，例如必须准确计算数千行代码，或对其编写的任何代码进行字符串转义。

一个经验法则是考虑在人机界面（HCI）上投入了多少精力，并计划在创建良好的代理-计算机界面（ACI）上投入同样多的精力。以下是一些关于如何做到这一点的想法：

- 站在模型的角度思考。根据描述和参数，使用此工具是否显而易见，还是您需要仔细思考？如果是后者，那么对模型来说可能也是如此。一个好的工具定义通常包括示例用法、边缘情况、输入格式要求以及与其他工具的明确界限。
- 您如何更改参数名称或描述以使事情更明显？将其视为为团队中的初级开发人员编写一个优秀的文档字符串。在使用许多类似工具时，这一点尤其重要。
- 测试模型如何使用您的工具：在我们的工作台中运行许多示例输入，看看模型犯了什么错误，并进行迭代。
- 防错您的工具。更改参数，使其更难犯错误。

在构建我们的 SWE-bench 代理时，我们实际上花了更多时间优化我们的工具，而不是整体提示。例如，我们发现当代理移出根目录后，模型在使用相对文件路径的工具时会犯错误。为了解决这个问题，我们将工具更改为始终需要绝对文件路径——我们发现模型使用这种方法时毫无瑕疵。
