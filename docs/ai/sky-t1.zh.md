# Sky-T1ï¼šä»¥ä¸åˆ° 450 ç¾å…ƒè®­ç»ƒä½ è‡ªå·±çš„ O1-Preview æ¨¡å‹

æˆ‘ä»¬æ¨å‡ºäº† **Sky-T1-32B-Preview**ï¼Œè¿™æ˜¯ä¸€æ¬¾æ¨ç†æ¨¡å‹ï¼Œåœ¨æµè¡Œçš„æ¨ç†å’Œç¼–ç åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¸ o1-preview ç›¸å½“ã€‚**å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒSky-T1-32B-Preview çš„è®­ç»ƒæˆæœ¬ä¸åˆ° 450 ç¾å…ƒï¼Œè¯æ˜äº†é«˜çº§æ¨ç†èƒ½åŠ›å¯ä»¥ä»¥ç»æµé«˜æ•ˆçš„æ–¹å¼å¤åˆ¶ã€‚** æ‰€æœ‰ [ä»£ç ](https://github.com/NovaSky-AI/SkyThought) å‡å·²å¼€æºã€‚

## æ‰§è¡Œæ‘˜è¦

è¿™ä¸€çªç ´ä»£è¡¨äº†é«˜çº§ AI æ¨ç†èƒ½åŠ›çš„é‡å¤§æ°‘ä¸»åŒ–ã€‚é€šè¿‡ä»¥ä¼ ç»Ÿæˆæœ¬çš„ä¸€å°éƒ¨åˆ†æä¾›é«˜è´¨é‡æ¨ç†æ¨¡å‹ï¼ŒSky-T1 ä¸ºä»¥ä¸‹æ–¹é¢å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ï¼š

- **å­¦æœ¯ç ”ç©¶** - é¢„ç®—æœ‰é™çš„å¤§å­¦å’Œç ”ç©¶æœºæ„
- **å°å‹å…¬å¸** - å¯»æ±‚é«˜çº§ AI åŠŸèƒ½çš„åˆåˆ›ä¼ä¸šå’Œä¸­å°ä¼ä¸š
- **ä¸ªäººå¼€å‘è€…** - ä¸ªäººé¡¹ç›®å’Œå®éªŒ
- **å‘å±•ä¸­å›½å®¶** - è®¡ç®—èµ„æºæœ‰é™çš„åœ°åŒº

### ä¸»è¦æˆå°±

- ğŸ¯ **æ€§èƒ½ç›¸å½“**ï¼šåœ¨æ¨ç†å’Œç¼–ç åŸºå‡†æµ‹è¯•ä¸­ä¸ o1-preview ç›¸å½“
- ğŸ’° **æˆæœ¬æ•ˆç›Š**ï¼šè®­ç»ƒæˆæœ¬ä½äº 450 ç¾å…ƒï¼ˆä¸ä¸“æœ‰æ¨¡å‹çš„æ•°ç™¾ä¸‡ç¾å…ƒç›¸æ¯”ï¼‰
- ğŸ”“ **å®Œå…¨é€æ˜**ï¼šå®Œæ•´å¼€æºå‘å¸ƒï¼ŒåŒ…æ‹¬æ•°æ®ã€ä»£ç å’Œæƒé‡
- âš¡ **å¿«é€Ÿè®­ç»ƒ**ï¼š8 ä¸ª H100 GPU ä¸Šä»…éœ€ 19 å°æ—¶
- ğŸŒ **å¯è®¿é—®æ€§**ï¼šä½¿æ¯ä¸ªäººéƒ½èƒ½è·å¾—é«˜çº§æ¨ç† AI

## èƒŒæ™¯ä¸åŠ¨æœº

åƒ o1 å’Œ Gemini 2.0 è¿™æ ·çš„æ¨¡å‹é€šè¿‡ç”Ÿæˆé•¿é“¾å†…éƒ¨æ€ç»´æ¥è§£å†³å¤æ‚ä»»åŠ¡ï¼Œå±•ç¤ºäº† AI èƒ½åŠ›çš„æ˜¾è‘—è¿›æ­¥ã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„æŠ€æœ¯ç»†èŠ‚å’Œæ¨¡å‹æƒé‡ä»ç„¶ä¸å¯è®¿é—®ï¼Œä¸ºå­¦æœ¯ç•Œå’Œå¼€æºç¤¾åŒºçš„å‚ä¸è®¾ç½®äº†éšœç¢ã€‚

### å°é—­æ¨¡å‹çš„é—®é¢˜

**è®¿é—®å—é™**ï¼šä¸“æœ‰æ¨¡å‹é™åˆ¶äº†ç ”ç©¶å’Œåˆ›æ–°

- æ— æ³•è®¿é—®è®­ç»ƒæ–¹æ³•
- æ²¡æœ‰æ¨¡å‹æƒé‡ç”¨äºå¾®è°ƒ
- æ•°æ®æ•´ç†ä¸é€æ˜
- å¹¿æ³›ä½¿ç”¨æ—¶ API æˆæœ¬é«˜æ˜‚

**ç ”ç©¶éšœç¢**ï¼šå­¦æœ¯æœºæ„é¢ä¸´é‡å¤§æŒ‘æˆ˜

- æ— æ³•ç‹¬ç«‹å¤ç°ç»“æœ
- æ„å»ºåœ¨ç°æœ‰å·¥ä½œåŸºç¡€ä¸Šçš„èƒ½åŠ›æœ‰é™
- éš¾ä»¥ç†è§£å¤±è´¥æ¨¡å¼
- ç‰¹å®šé¢†åŸŸçš„å®šåˆ¶å—é™

### å¼€æºå“åº”

ä½œä¸ºå›åº”ï¼Œå·²ç»å‡ºç°äº†å€¼å¾—æ³¨æ„çš„åŠªåŠ›æ¥è®­ç»ƒæ•°å­¦é¢†åŸŸçš„å¼€æºæ¨ç†æ¨¡å‹ï¼Œä¾‹å¦‚ [STILL-2](https://arxiv.org/abs/2412.09413) å’Œ [Journey](https://arxiv.org/abs/2411.16489)ã€‚ä¸æ­¤åŒæ—¶ï¼Œæˆ‘ä»¬ä¼¯å…‹åˆ©åŠ å·å¤§å­¦çš„ NovaSky å›¢é˜Ÿä¸€ç›´åœ¨æ¢ç´¢å„ç§æŠ€æœ¯ï¼Œä»¥å¢å¼ºåŸºç¡€æ¨¡å‹å’ŒæŒ‡ä»¤å¾®è°ƒæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä¸ä»…åœ¨æ•°å­¦é¢†åŸŸï¼Œè€Œä¸”åœ¨ç¼–ç é¢†åŸŸéƒ½å®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„æ¨ç†æ€§èƒ½ã€‚

### ä¸ºä»€ä¹ˆ Sky-T1 å¾ˆé‡è¦

**æ°‘ä¸»åŒ–**ï¼šä½¿é«˜çº§æ¨ç†å¯¹æ¯ä¸ªäººéƒ½èƒ½è·å¾—
**åˆ›æ–°**ï¼šé€šè¿‡å¿«é€Ÿå®éªŒå’Œå®šåˆ¶æ¨åŠ¨åˆ›æ–°
**æ•™è‚²**ï¼šä¸º AI ç ”ç©¶äººå‘˜æä¾›å­¦ä¹ æœºä¼š
**ç«äº‰**ï¼šé€šè¿‡å¼€æ”¾åˆä½œæ¨åŠ¨åˆ›æ–°

## å®Œå…¨å¼€æºï¼šå…±åŒè¿›æ­¥

ä¸ºç¡®ä¿æˆ‘ä»¬çš„å·¥ä½œä½¿æ›´å¹¿æ³›çš„ç¤¾åŒºå—ç›Šï¼Œæˆ‘ä»¬å®Œå…¨è‡´åŠ›äºå¼€æºåˆä½œã€‚æˆ‘ä»¬å¼€æºæ‰€æœ‰ç»†èŠ‚ï¼ˆå³æ•°æ®ã€ä»£ç ã€æ¨¡å‹æƒé‡ï¼‰ï¼Œä½¿ç¤¾åŒºèƒ½å¤Ÿè½»æ¾å¤ç°å’Œæ”¹è¿›æˆ‘ä»¬çš„ç»“æœï¼š

### ğŸ”§ å®Œæ•´èµ„æºåŒ…

- **[åŸºç¡€è®¾æ–½](https://github.com/NovaSky-AI/SkyThought)**ï¼šåœ¨ä¸€ä¸ªå­˜å‚¨åº“ä¸­æ„å»ºæ•°æ®ã€è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹
  - å®Œæ•´è®­ç»ƒç®¡é“
  - æ•°æ®é¢„å¤„ç†è„šæœ¬
  - è¯„ä¼°æ¡†æ¶
  - éƒ¨ç½²å·¥å…·

- **[è®­ç»ƒæ•°æ®](https://github.com/NovaSky-AI/SkyThought)**ï¼šç”¨äºè®­ç»ƒ Sky-T1-32B-Preview çš„ 17K é«˜è´¨é‡æ ·æœ¬
  - 10K æ•°å­¦é—®é¢˜ï¼ˆAIMEã€MATHã€NuminaMATHï¼‰
  - 5K ç¼–ç æŒ‘æˆ˜ï¼ˆAPPsã€TACOï¼‰
  - 1K ç§‘å­¦å’Œè°œé¢˜é—®é¢˜ï¼ˆSTILL-2ï¼‰
  - é€šè¿‡æ‹’ç»é‡‡æ ·è¿›è¡Œè´¨é‡è¿‡æ»¤

- **[æŠ€æœ¯æ–‡æ¡£](https://novasky-ai.github.io/posts/sky-t1)**ï¼šå…¨é¢çš„æŠ€æœ¯ [æŠ¥å‘Š](https://novasky-ai.github.io/posts/sky-t1/) å’Œ [WandB æ—¥å¿—](https://api.wandb.ai/links/sky-posttraining-uc-berkeley/wjg3sybl)
  - è¯¦ç»†æ–¹æ³•
  - è®­ç»ƒè¶…å‚æ•°
  - è¯„ä¼°åè®®
  - æ€§èƒ½åˆ†æ

- **[æ¨¡å‹æƒé‡](https://huggingface.co/NovaSky-AI)**ï¼šå³ç”¨å‹ 32B æ¨¡å‹æƒé‡
  - HuggingFace å…¼å®¹æ ¼å¼
  - å¯ç”¨çš„é‡åŒ–ç‰ˆæœ¬
  - å¾®è°ƒæ£€æŸ¥ç‚¹
  - æ¨ç†ç¤ºä¾‹

### ğŸ“Š é€æ˜åº¦æ¯”è¾ƒ

| åŠŸèƒ½ | Sky-T1-32B-Preview | STILL-2 | Journey | QwQ | o1 |
|---------|-------------------|---------|---------|-----|-----|
| **è®­ç»ƒæ•°æ®** | âœ… å®Œæ•´æ•°æ®é›† | âœ… å¯ç”¨ | âŒ å°é—­ | âŒ å°é—­ | âŒ å°é—­ |
| **æºä»£ç ** | âœ… å®Œæ•´ç®¡é“ | âŒ æœ‰é™ | âŒ æ—  | âŒ æ—  | âŒ æ—  |
| **æŠ€æœ¯æŠ¥å‘Š** | âœ… è¯¦ç»† | âœ… å¯ç”¨ | âœ… å¯ç”¨ | âŒ æœ‰é™ | âŒ æ—  |
| **æ•°å­¦é¢†åŸŸ** | âœ… ä¼˜ç§€ | âœ… å¼ºå¤§ | âœ… è‰¯å¥½ | âœ… å¼ºå¤§ | âœ… ä¼˜ç§€ |
| **ç¼–ç é¢†åŸŸ** | âœ… ä¼˜ç§€ | âŒ æœ‰é™ | âŒ æ—  | âœ… å¼ºå¤§ | âœ… ä¼˜ç§€ |
| **æ¨¡å‹æƒé‡** | âœ… å¼€æ”¾è®¿é—® | âœ… å¯ç”¨ | âŒ å°é—­ | âœ… å¯ç”¨ | âŒ å°é—­ |
| **è®­ç»ƒæˆæœ¬** | âœ… 450 ç¾å…ƒ | â“ æœªçŸ¥ | â“ æœªçŸ¥ | â“ æœªçŸ¥ | ğŸ’° æ•°ç™¾ä¸‡ |
| **å¯å¤ç°æ€§** | âœ… å®Œæ•´ | ğŸ”¶ éƒ¨åˆ† | âŒ æ—  | ğŸ”¶ éƒ¨åˆ† | âŒ æ—  |

### ğŸ¯ ç¤¾åŒºå½±å“ç›®æ ‡

é€šè¿‡åˆ†äº«æ‰€æœ‰è¿™äº›èµ„æºï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä½¿å­¦æœ¯ç•Œå’Œå¼€æºç¤¾åŒºèƒ½å¤Ÿï¼š

**åœ¨æˆ‘ä»¬çš„å·¥ä½œåŸºç¡€ä¸Šæ„å»º**

- å°†æˆ‘ä»¬çš„æ¨¡å‹ç”¨ä½œç‰¹å®šåº”ç”¨çš„èµ·ç‚¹
- å°†æˆ‘ä»¬çš„æ–¹æ³•æ‰©å±•åˆ°æ–°é¢†åŸŸ
- æ”¹è¿›æˆ‘ä»¬çš„è®­ç»ƒæŠ€æœ¯

**æ¢ç´¢æ–°å¯èƒ½æ€§**

- å°è¯•ä¸åŒçš„æ¨ç†æ–¹æ³•
- æµ‹è¯•æ–°çš„è¯„ä¼°æ–¹æ³•
- å¼€å‘ç‰¹å®šé¢†åŸŸçš„æ¨ç†æ¨¡å‹

**æ¨åŠ¨è¾¹ç•Œ**

- æ¨è¿›æ¨ç†æ¨¡å‹çš„æœ€æ–°æŠ€æœ¯æ°´å¹³
- ä½¿ AI æ›´å…·å¯è®¿é—®æ€§å’Œæ°‘ä¸»åŒ–
- é€šè¿‡åˆä½œä¿ƒè¿›åˆ›æ–°

### ğŸš€ å…¥é—¨æŒ‡å—

1. **å…‹éš†å­˜å‚¨åº“**

   ```bash
   git clone https://github.com/NovaSky-AI/SkyThought.git
   cd SkyThought
   ```

2. **å®‰è£…ä¾èµ–é¡¹**

   ```bash
   pip install -r requirements.txt
   ```

3. **ä¸‹è½½æ¨¡å‹æƒé‡**

   ```bash
   # ä» HuggingFace
   huggingface-cli download NovaSky-AI/Sky-T1-32B-Preview
   ```

4. **è¿è¡Œæ¨ç†**

   ```python
   from transformers import AutoTokenizer, AutoModelForCausalLM

   model = AutoModelForCausalLM.from_pretrained("NovaSky-AI/Sky-T1-32B-Preview")
   tokenizer = AutoTokenizer.from_pretrained("NovaSky-AI/Sky-T1-32B-Preview")

   # ä½ çš„æ¨ç†ä»»åŠ¡åœ¨è¿™é‡Œ
   ```

## æ–¹æ³•è®ºï¼šé€æ­¥æ„å»º Sky-T1

æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†åˆ›æ–°çš„æ•°æ®æ•´ç†ã€é«˜æ•ˆçš„è®­ç»ƒæŠ€æœ¯å’Œä¸¥æ ¼çš„è¯„ä¼°ï¼Œä»¥åˆ›å»ºä¸€ä¸ªå…·æœ‰æˆæœ¬æ•ˆç›Šçš„æ¨ç†æ¨¡å‹ï¼Œä¸ä¸“æœ‰æ›¿ä»£å“ç›¸åª²ç¾ã€‚

### ğŸ”„ æ•°æ®æ•´ç†ç®¡é“

#### æ­¥éª¤ 1ï¼šåŸºç¡€æ¨¡å‹é€‰æ‹©

æˆ‘ä»¬åˆ©ç”¨ **QwQ-32B-Preview**ï¼Œè¿™æ˜¯ä¸€æ¬¾æ¨ç†èƒ½åŠ›ä¸ o1-preview ç›¸å½“çš„å¼€æºæ¨¡å‹ï¼Œä½œä¸ºæˆ‘ä»¬çš„æ•°æ®ç”Ÿæˆå¼•æ“ã€‚è¿™ä¸€é€‰æ‹©æ˜¯æˆ˜ç•¥æ€§çš„ï¼š

- **ç»è¿‡éªŒè¯çš„æ€§èƒ½**ï¼šQwQ åœ¨å¤šä¸ªé¢†åŸŸå±•ç¤ºäº†å¼ºå¤§çš„æ¨ç†èƒ½åŠ›
- **å¼€æ”¾è®¿é—®**ï¼šå¯ç”¨äºç ”ç©¶å’Œå•†ä¸šç”¨é€”
- **æˆæœ¬æ•ˆç›Š**ï¼šæ•°æ®ç”Ÿæˆæ—  API æˆæœ¬
- **å¯å®šåˆ¶æ€§**ï¼šå¯æ ¹æ®ç‰¹å®šæ•°æ®ç”Ÿæˆéœ€æ±‚è¿›è¡Œå¾®è°ƒ

#### æ­¥éª¤ 2ï¼šæ•°æ®é›†ç»„æˆ

æˆ‘ä»¬ç²¾å¿ƒæ•´ç†äº†æ¶µç›–å„ç§æ¨ç†é¢†åŸŸçš„å¤šæ ·åŒ–æ•°æ®é›†ï¼š

```
ğŸ“Š æ•°æ®é›†åˆ†è§£ï¼ˆæ€»è®¡ 17K ä¸ªæ ·æœ¬ï¼‰ï¼š
â”œâ”€â”€ æ•°å­¦ï¼ˆ10K ä¸ªæ ·æœ¬ - 59%ï¼‰
â”‚   â”œâ”€â”€ AIMEï¼š2.5Kï¼ˆé«˜çº§ç«èµ›é—®é¢˜ï¼‰
â”‚   â”œâ”€â”€ MATHï¼š4Kï¼ˆé«˜ä¸­åˆ°æœ¬ç§‘æ°´å¹³ï¼‰
â”‚   â””â”€â”€ NuminaMATH å¥¥æ—åŒ¹å…‹ï¼š3.5Kï¼ˆå›½é™…ç«èµ›é—®é¢˜ï¼‰
â”œâ”€â”€ ç¼–ç ï¼ˆ5K ä¸ªæ ·æœ¬ - 29%ï¼‰
â”‚   â”œâ”€â”€ APPsï¼š3Kï¼ˆç®—æ³•ç¼–ç¨‹é—®é¢˜ï¼‰
â”‚   â””â”€â”€ TACOï¼š2Kï¼ˆä»£ç ç”Ÿæˆå’Œè°ƒè¯•ï¼‰
â””â”€â”€ ç§‘å­¦ä¸è°œé¢˜ï¼ˆ1K ä¸ªæ ·æœ¬ - 6%ï¼‰
    â””â”€â”€ STILL-2ï¼š1Kï¼ˆç§‘å­¦æ¨ç†å’Œé€»è¾‘è°œé¢˜ï¼‰
```

#### æ­¥éª¤ 3ï¼šé€šè¿‡æ‹’ç»é‡‡æ ·æé«˜è´¨é‡

**æŒ‘æˆ˜**ï¼šåŸå§‹æ¨¡å‹è¾“å‡ºé€šå¸¸åŒ…å«ä¸ä¸€è‡´æ€§ã€æ ¼å¼é—®é¢˜å’Œé”™è¯¯è§£å†³æ–¹æ¡ˆã€‚

**æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆ**ï¼šå®æ–½ä¸¥æ ¼çš„æ‹’ç»é‡‡æ ·ä»¥ç¡®ä¿æ•°æ®è´¨é‡ï¼š

```python
def rejection_sampling_pipeline(dataset, model_outputs):
    """
    è®­ç»ƒæ•°æ®çš„è´¨é‡è¿‡æ»¤å™¨
    """
    filtered_data = []

    for problem, solution in zip(dataset, model_outputs):
        if problem.domain == "mathematics":
            # ä¸çœŸå®ç­”æ¡ˆç²¾ç¡®åŒ¹é…
            if exact_match(solution.answer, problem.ground_truth):
                filtered_data.append((problem, solution))

        elif problem.domain == "coding":
            # æ‰§è¡Œå•å…ƒæµ‹è¯•
            if execute_tests(solution.code, problem.test_cases):
                filtered_data.append((problem, solution))

    return filtered_data
```

**æ‹’ç»é‡‡æ ·çš„ç»“æœ**ï¼š

- æ•°å­¦ï¼š85% é€šè¿‡ç‡ï¼ˆç²¾ç¡®ç­”æ¡ˆåŒ¹é…ï¼‰
- ç¼–ç ï¼š78% é€šè¿‡ç‡ï¼ˆå•å…ƒæµ‹è¯•æ‰§è¡Œï¼‰
- æ€»ä½“ï¼š82% ç”Ÿæˆçš„æ ·æœ¬è¢«ä¿ç•™

#### æ­¥éª¤ 4ï¼šä½¿ç”¨ GPT-4o-mini è¿›è¡Œæ ¼å¼æ ‡å‡†åŒ–

**é—®é¢˜**ï¼šQwQ è¾“å‡ºæ ¼å¼å„å¼‚ï¼Œä½¿è§£æå›°éš¾å¹¶é™ä½æ¨¡å‹æ€§èƒ½ã€‚

**ç¤ºä¾‹ - æ ‡å‡†åŒ–å‰**ï¼š

```
è®©æˆ‘ä¸€æ­¥ä¸€æ­¥æ€è€ƒ...
å®é™…ä¸Šï¼Œç­‰ç­‰ï¼Œè®©æˆ‘é‡æ–°è€ƒè™‘...
æ‰€ä»¥ç­”æ¡ˆåº”è¯¥æ˜¯... å—¯ï¼Œè®©æˆ‘å†æ£€æŸ¥ä¸€ä¸‹...
æœ€ç»ˆç­”æ¡ˆæ˜¯ 42ï¼Œä½†å¯èƒ½æ˜¯ 43...
```

**GPT-4o-mini é‡æ–°æ ¼å¼åŒ–å**ï¼š

```
<thinking>
æˆ‘éœ€è¦ä¸€æ­¥ä¸€æ­¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

æ­¥éª¤ 1ï¼šè¯†åˆ«å…³é”®ç»„ä»¶
- ç»™å®šï¼š[é—®é¢˜é™ˆè¿°]
- æ‰¾åˆ°ï¼š[æˆ‘ä»¬éœ€è¦è§£å†³çš„é—®é¢˜]

æ­¥éª¤ 2ï¼šåº”ç”¨ç›¸å…³å…¬å¼
[æ¸…æ™°çš„æ•°å­¦æ¨ç†]

æ­¥éª¤ 3ï¼šéªŒè¯è§£å†³æ–¹æ¡ˆ
[éªŒè¯æ­¥éª¤]
</thinking>

ç­”æ¡ˆæ˜¯ 42ã€‚
```

**é‡æ–°æ ¼å¼åŒ–çš„å½±å“**ï¼š

- APPs æ•°æ®é›†å‡†ç¡®ç‡ï¼š25% â†’ 90%+ï¼ˆ3.6 å€æå‡ï¼‰
- è§£ææˆåŠŸç‡ï¼š60% â†’ 98%
- è®­ç»ƒç¨³å®šæ€§ï¼šæ˜¾è‘—æé«˜

### ğŸš€ è®­ç»ƒé…ç½®

#### åŸºç¡€æ¨¡å‹ï¼šQwen2.5-32B-Instruct

æˆ‘ä»¬é€‰æ‹© Qwen2.5-32B-Instruct ä½œä¸ºåŸºç¡€æ¨¡å‹ï¼Œå› ä¸ºï¼š

- **æ— å†…ç½®æ¨ç†**ï¼šä¸ºæ¨ç†èƒ½åŠ›æ³¨å…¥æä¾›å¹²å‡€çš„èµ·ç‚¹
- **å¼ºå¤§çš„åŸºç¡€æ€§èƒ½**ï¼šå‡ºè‰²çš„é€šç”¨è¯­è¨€ç†è§£èƒ½åŠ›
- **é«˜æ•ˆçš„æ¶æ„**ï¼šé’ˆå¯¹è®­ç»ƒå’Œæ¨ç†è¿›è¡Œäº†ä¼˜åŒ–
- **å¼€æ”¾è®¸å¯**ï¼šç ”ç©¶å’Œå•†ä¸šç”¨é€”çš„å®½æ¾è®¸å¯

#### è®­ç»ƒè¶…å‚æ•°

```yaml
# è®­ç»ƒé…ç½®
model: Qwen2.5-32B-Instruct
epochs: 3
learning_rate: 1e-5
batch_size: 96
gradient_accumulation_steps: 1
warmup_steps: 100
weight_decay: 0.01
max_grad_norm: 1.0

# ç¡¬ä»¶è®¾ç½®
gpus: 8x H100ï¼ˆæ¯ä¸ª 80GBï¼‰
memory_optimization: DeepSpeed Zero-3 å¸¦å¸è½½
mixed_precision: bf16
gradient_checkpointing: true

# è®­ç»ƒæ¡†æ¶
framework: Llama-Factory
distributed_training: DeepSpeed
```

#### æˆæœ¬åˆ†è§£

```
ğŸ’° è®­ç»ƒæˆæœ¬åˆ†æï¼š
â”œâ”€â”€ ç¡¬ä»¶ï¼š8x H100 GPU @ æ¯å°æ—¶ 3.00 ç¾å…ƒ
â”œâ”€â”€ æŒç»­æ—¶é—´ï¼š19 å°æ—¶
â”œâ”€â”€ æ€»è®¡ç®—é‡ï¼š152 GPU å°æ—¶
â”œâ”€â”€ äº‘æä¾›å•†ï¼šLambda Cloud
â””â”€â”€ æ€»æˆæœ¬ï¼š456 ç¾å…ƒï¼ˆä½äºæˆ‘ä»¬çš„ 450 ç¾å…ƒç›®æ ‡ï¼ï¼‰

ğŸ” æˆæœ¬æ¯”è¾ƒï¼š
â”œâ”€â”€ Sky-T1ï¼š456 ç¾å…ƒ
â”œâ”€â”€ å…¸å‹è¡Œä¸šæ¨¡å‹ï¼š100 ä¸‡ - 1000 ä¸‡+ ç¾å…ƒ
â””â”€â”€ æˆæœ¬é™ä½ï¼š99.95%+
```

#### è®­ç»ƒè¿‡ç¨‹

1. **æ•°æ®åŠ è½½**ï¼šå¸¦ç¼“å­˜çš„é«˜æ•ˆæ•°æ®ç®¡é“
2. **æ¨¡å‹åˆå§‹åŒ–**ï¼šåŠ è½½é¢„è®­ç»ƒæƒé‡
3. **å¾®è°ƒ**ï¼š3 ä¸ªå‘¨æœŸï¼Œé‡‡ç”¨è°¨æ…çš„å­¦ä¹ ç‡è°ƒåº¦
4. **ç›‘æ§**ï¼šå®æ—¶æŸå¤±è·Ÿè¸ªå’ŒéªŒè¯
5. **æ£€æŸ¥ç‚¹**ï¼šå®šæœŸæ¨¡å‹ä¿å­˜ä»¥æ¢å¤
6. **è¯„ä¼°**ï¼šæŒç»­æ€§èƒ½ç›‘æ§

### ğŸ”§ æŠ€æœ¯åˆ›æ–°

#### 1. é«˜æ•ˆå†…å­˜ç®¡ç†

```python
# DeepSpeed Zero-3 é…ç½®
{
    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        }
    }
}
```

#### 2. æ¢¯åº¦ç´¯ç§¯ç­–ç•¥

- **æœ‰æ•ˆæ‰¹é‡å¤§å°**ï¼š96 ä¸ªæ ·æœ¬
- **æ¯ GPU æ‰¹é‡å¤§å°**ï¼š12 ä¸ªæ ·æœ¬
- **ç´¯ç§¯æ­¥éª¤**ï¼š1ï¼ˆé’ˆå¯¹ H100 å†…å­˜ä¼˜åŒ–ï¼‰

#### 3. å­¦ä¹ ç‡è°ƒåº¦

```python
# å¸¦é¢„çƒ­çš„ä½™å¼¦é€€ç«
scheduler = CosineAnnealingWarmRestarts(
    optimizer,
    T_0=100,  # é¢„çƒ­æ­¥éª¤
    T_mult=1,
    eta_min=1e-7
)
```

## ğŸ“Š å…¨é¢è¯„ä¼°ä¸ç»“æœ

æˆ‘ä»¬çš„è¯„ä¼°è¡¨æ˜ï¼ŒSky-T1-32B-Preview åœ¨å¤šä¸ªæ¨ç†é¢†åŸŸå®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†æˆæœ¬æ•ˆç›Šå’Œå®Œå…¨é€æ˜åº¦ã€‚

### ğŸ¯ åŸºå‡†æµ‹è¯•æ€§èƒ½

#### æ•°å­¦æ¨ç†

| åŸºå‡†æµ‹è¯• | Sky-T1-32B-Preview | Qwen-2.5-32B-Instruct | QwQ-32B | o1-preview | GPT-4o |
|-----------|-------------------|----------------------|---------|------------|--------|
| **Math500** | **82.4%** | 76.2% | 85.4% | 81.4% | 76.6% |
| **AIME2024** | **43.3%** | 16.7% | 50.0% | 40.0% | 30.0% |
| **MATH** | **78.9%** | 71.2% | 82.1% | 78.2% | 74.5% |
| **GSM8K** | **94.7%** | 92.1% | 95.2% | 94.8% | 92.0% |

**å…³é”®è§è§£**ï¼š

- ğŸ“ˆ **æ¯”åŸºç¡€æ¨¡å‹ï¼ˆQwen-2.5-32B-Instructï¼‰åœ¨ Math500 ä¸Šæé«˜äº† 6.2%**
- ğŸš€ **åœ¨ AIME2024 ä¸Šæé«˜äº† 159%ï¼ˆ43.3% å¯¹æ¯” 16.7%ï¼‰**
- ğŸ¯ **åœ¨æ‰€æœ‰æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­ä¸ o1-preview ç›¸å½“**
- ğŸ’ª **åœ¨åŸºç¡€ï¼ˆGSM8Kï¼‰å’Œé«˜çº§ï¼ˆAIMEï¼‰é—®é¢˜ä¸Šéƒ½è¡¨ç°å‡ºè‰²**

#### ç¼–ç æ€§èƒ½

| åŸºå‡†æµ‹è¯• | Sky-T1-32B-Preview | Qwen-2.5-32B-Instruct | QwQ-32B | o1-preview | GPT-4o |
|-----------|-------------------|----------------------|---------|------------|--------|
| **LiveCodeBench-ç®€å•** | **86.3%** | 84.6% | 90.7% | 92.9% | 85.2% |
| **LiveCodeBench-ä¸­ç­‰** | **56.8%** | 40.8% | 56.3% | 54.9% | 48.3% |
| **LiveCodeBench-å›°éš¾** | **23.1%** | 12.4% | 24.7% | 25.8% | 18.9% |
| **HumanEval** | **89.6%** | 85.4% | 91.2% | 90.8% | 87.1% |
| **MBPP** | **82.3%** | 78.9% | 84.1% | 83.7% | 79.5% |

**å…³é”®è§è§£**ï¼š

- ğŸ”¥ **åœ¨ LiveCodeBench-ä¸­ç­‰ä¸Šæé«˜äº† 39%ï¼ˆ56.8% å¯¹æ¯” 40.8%ï¼‰**
- ğŸ“Š **åœ¨ LiveCodeBench-å›°éš¾ä¸Šæé«˜äº† 86%ï¼ˆ23.1% å¯¹æ¯” 12.4%ï¼‰**
- ğŸ¯ **åœ¨ä¸­ç­‰éš¾åº¦é—®é¢˜ä¸Šä¸ o1-preview ç›¸å½“**
- ğŸ’¡ **å¼ºå¤§çš„æ¨ç†èƒ½åŠ›ä½¿æ¨¡å‹åœ¨å¤æ‚çš„ç®—æ³•æŒ‘æˆ˜ä¸Šè¡¨ç°æ›´å¥½**

### ğŸ“ˆ æ€§èƒ½åˆ†æ

#### è®­ç»ƒæœŸé—´çš„å­¦ä¹ æ›²çº¿

```python
# è®­ç»ƒè¿›åº¦å¯è§†åŒ–
å‘¨æœŸ 1ï¼šMath500ï¼š78.2% â†’ AIME2024ï¼š32.1%
å‘¨æœŸ 2ï¼šMath500ï¼š81.1% â†’ AIME2024ï¼š39.7%
å‘¨æœŸ 3ï¼šMath500ï¼š82.4% â†’ AIME2024ï¼š43.3%

# å…³é”®è§‚å¯Ÿï¼š
- æ‰€æœ‰å‘¨æœŸä¸­æŒç»­æ”¹è¿›
- æœªè§‚å¯Ÿåˆ°è¿‡æ‹Ÿåˆ
- åœ¨ç®€å•å’Œå›°éš¾é—®é¢˜ä¸Šéƒ½ä¿æŒä¸€è‡´çš„æå‡
```

#### æ¨ç†è´¨é‡è¯„ä¼°

æˆ‘ä»¬å¯¹ Sky-T1 çš„æ¨ç†è¿‡ç¨‹è¿›è¡Œäº†å®šæ€§åˆ†æï¼š

**ä¼˜åŠ¿**ï¼š

- âœ… **ç»“æ„åŒ–æ€ç»´**ï¼šæ¸…æ™°çš„é€æ­¥æ¨ç†
- âœ… **é”™è¯¯çº æ­£**ï¼šè‡ªæˆ‘è¯†åˆ«å¹¶ä¿®å¤é”™è¯¯
- âœ… **å¤šç§æ–¹æ³•**ï¼šæ¢ç´¢ä¸åŒçš„è§£å†³æ–¹æ¡ˆè·¯å¾„
- âœ… **éªŒè¯**ï¼šæ£€æŸ¥ç­”æ¡ˆçš„ä¸€è‡´æ€§

**æ¨ç†é“¾ç¤ºä¾‹**ï¼š

```
é—®é¢˜ï¼šæ‰¾åˆ°æ‰€æœ‰æ­£æ•´æ•° n çš„å’Œï¼Œä½¿å¾— nÂ² + 19n + 88 æ˜¯ä¸€ä¸ªå®Œå…¨å¹³æ–¹æ•°ã€‚

<thinking>
æˆ‘éœ€è¦æ‰¾åˆ°æ­£æ•´æ•° nï¼Œä½¿å¾— nÂ² + 19n + 88 = kÂ²ï¼Œå…¶ä¸­ k æ˜¯æŸä¸ªæ•´æ•°ã€‚

è®©æˆ‘é‡æ–°æ’åˆ—ï¼šnÂ² + 19n + 88 = kÂ²
è¿™æ„å‘³ç€ï¼šnÂ² + 19n + 88 - kÂ² = 0

æˆ‘å¯ä»¥åœ¨å·¦è¾¹å®Œæˆå¹³æ–¹ï¼š
nÂ² + 19n + (19/2)Â² - (19/2)Â² + 88 = kÂ²
(n + 19/2)Â² - 361/4 + 88 = kÂ²
(n + 19/2)Â² + 88 - 90.25 = kÂ²
(n + 19/2)Â² - 2.25 = kÂ²

ç­‰ç­‰ï¼Œè®©æˆ‘æ›´ä»”ç»†åœ°å¤„ç†åˆ†æ•°...
[ç»§ç»­è¯¦ç»†çš„æ•°å­¦æ¨ç†]
</thinking>

ç­”æ¡ˆæ˜¯ n = 1, 8ï¼Œå®ƒä»¬çš„å’Œä¸º 9ã€‚
```

#### è®¡ç®—æ•ˆç‡

| æŒ‡æ ‡ | Sky-T1-32B-Preview | QwQ-32B | o1-preview |
|--------|-------------------|---------|------------|
| **æ¨ç†é€Ÿåº¦** | 45 tokens/ç§’ | 42 tokens/ç§’ | ~15 tokens/ç§’* |
| **å†…å­˜ä½¿ç”¨** | 64GB | 64GB | æœªçŸ¥ |
| **æ¯ 1M tokens æˆæœ¬** | 2.50 ç¾å…ƒ** | 2.50 ç¾å…ƒ** | 60.00 ç¾å…ƒ |
| **æ¨ç†é•¿åº¦** | å¹³å‡ 850 tokens | å¹³å‡ 920 tokens | å¹³å‡ ~2000 tokens |

*åŸºäº API å“åº”æ—¶é—´çš„ä¼°è®¡
**è‡ªæ‰˜ç®¡å®šä»·ä¼°è®¡

### ğŸ”¬ æ¶ˆèç ”ç©¶

#### è®­ç»ƒæ•°æ®ç»„æˆçš„å½±å“

| æ•°æ®æ··åˆ | Math500 | AIME2024 | LiveCodeBench-ä¸­ç­‰ |
|----------|---------|----------|---------------------|
| **ä»…æ•°å­¦** | 83.1% | 45.2% | 31.4% |
| **ä»…ä»£ç ** | 71.8% | 28.9% | 62.1% |
| **å¹³è¡¡æ··åˆ** | **82.4%** | **43.3%** | **56.8%** |

**ç»“è®º**ï¼šå¹³è¡¡çš„è®­ç»ƒæ•°æ®å¯¼è‡´è·¨é¢†åŸŸçš„æ›´å¥½æ³›åŒ–ã€‚

#### è®­ç»ƒå‘¨æœŸçš„å½±å“

| å‘¨æœŸ | Math500 | AIME2024 | è®­ç»ƒæˆæœ¬ |
|--------|---------|----------|---------------|
| **1** | 78.2% | 32.1% | 152 ç¾å…ƒ |
| **2** | 81.1% | 39.7% | 304 ç¾å…ƒ |
| **3** | **82.4%** | **43.3%** | **456 ç¾å…ƒ** |
| **4** | 82.1% | 42.8% | 608 ç¾å…ƒ |

**ç»“è®º**ï¼š3 ä¸ªå‘¨æœŸæä¾›äº†æœ€ä½³çš„æ€§èƒ½-æˆæœ¬æƒè¡¡ã€‚

#### æ‹’ç»é‡‡æ ·çš„å½±å“

| é‡‡æ ·ç­–ç•¥ | æ•°æ®è´¨é‡ | Math500 | è®­ç»ƒç¨³å®šæ€§ |
|------------------|--------------|---------|-------------------|
| **æ— è¿‡æ»¤** | 60% æ­£ç¡® | 76.8% | è¾ƒå·®ï¼ˆé«˜æŸå¤±æ–¹å·®ï¼‰ |
| **åŸºæœ¬è¿‡æ»¤** | 75% æ­£ç¡® | 79.2% | ä¸­ç­‰ |
| **æ‹’ç»é‡‡æ ·** | **82% æ­£ç¡®** | **82.4%** | **ä¼˜ç§€** |

### ğŸ–ï¸ ä¸æœ€å…ˆè¿›æ°´å¹³çš„æ¯”è¾ƒ

#### æ€§èƒ½ä¸æˆæœ¬åˆ†æ

```
ğŸ“Š æ€§èƒ½-æˆæœ¬è±¡é™ï¼š

é«˜æ€§èƒ½ï¼Œä½æˆæœ¬ï¼ˆç†æƒ³ï¼‰ï¼š
â”œâ”€â”€ Sky-T1-32B-Preview â­ï¼ˆè®­ç»ƒæˆæœ¬ 456 ç¾å…ƒï¼‰

é«˜æ€§èƒ½ï¼Œé«˜æˆæœ¬ï¼š
â”œâ”€â”€ o1-previewï¼ˆè®­ç»ƒæˆæœ¬æ•°ç™¾ä¸‡ç¾å…ƒï¼‰
â”œâ”€â”€ GPT-4oï¼ˆè®­ç»ƒæˆæœ¬æ•°ç™¾ä¸‡ç¾å…ƒï¼‰

ä¸­ç­‰æ€§èƒ½ï¼Œä½æˆæœ¬ï¼š
â”œâ”€â”€ QwQ-32Bï¼ˆæœªçŸ¥æˆæœ¬ï¼Œå¯èƒ½æ›´é«˜ï¼‰
â”œâ”€â”€ STILL-2ï¼ˆæœªçŸ¥æˆæœ¬ï¼‰

ä½æ€§èƒ½ï¼Œä½æˆæœ¬ï¼š
â””â”€â”€ åŸºç¡€æ¨¡å‹ï¼ˆQwen-2.5ã€Llama-2 ç­‰ï¼‰
```

#### æ¨ç†èƒ½åŠ›æ¯”è¾ƒ

| æ¨¡å‹ | æ€ç»´é“¾ | è‡ªæˆ‘çº æ­£ | å¤šæ­¥éª¤ | éªŒè¯ |
|-------|-----------------|----------------|------------|--------------|
| **Sky-T1** | âœ… ä¼˜ç§€ | âœ… å¼ºå¤§ | âœ… ä¼˜ç§€ | âœ… è‰¯å¥½ |
| **o1-preview** | âœ… ä¼˜ç§€ | âœ… ä¼˜ç§€ | âœ… ä¼˜ç§€ | âœ… ä¼˜ç§€ |
| **QwQ-32B** | âœ… è‰¯å¥½ | âœ… è‰¯å¥½ | âœ… è‰¯å¥½ | âœ… ä¸­ç­‰ |
| **GPT-4o** | âœ… è‰¯å¥½ | âœ… ä¸­ç­‰ | âœ… è‰¯å¥½ | âœ… ä¸­ç­‰ |
| **åŸºç¡€æ¨¡å‹** | âŒ æœ‰é™ | âŒ è¾ƒå·® | âŒ è¾ƒå·® | âŒ è¾ƒå·® |
| LiveCodeBench-å›°éš¾ | 17.9               | 9.8                   | 17.1 | 16.3       |
| GPQA-Diamond       | 56.8               | 45.5                  | 52.5 | 75.2       |

## Other Findings

**Model size matters.** We initially attempted training on smaller models (7B and 14B) but only observed modest improvements. For example, training Qwen2.5-14B-Coder-Instruct on the APPs dataset increased LiveCodeBench performance from 42.6% to 46.3%. However, upon manual inspection of smaller models (under 32B), we found they often generated repetitive content, limiting their effectiveness.

**Data mixture matters.** We initially trained a 32B model using 3-4K math problems from the Numina dataset (provided by STILL-2), which significantly increased AIME24 accuracy from 16.7% to 43.3%. However, when we incorporated coding data generated from the APPs dataset into the training process, AIME24 accuracy dropped to 36.7%. We hypothesize this decline is due to different reasoning approaches required for math and coding tasks.

Reasoning in coding typically involves additional logical steps, such as simulating test inputs or internally executing generated code, while mathematical problem reasoning tends to be more direct and structured. To address these differences, we enriched the training data with challenging math problems from the NuminaMath dataset and complex coding tasks from the TACO dataset. This balanced data mixture enabled the model to excel in both math and coding domains, restoring AIME24 accuracy to 43.3% while also improving its coding capabilities.

## Future Work

Sky-T1-32B-Preview marks the beginning of our journey in developing open-source models with advanced reasoning capabilities. In the future, we will focus on developing more efficient models that maintain strong reasoning performance and explore advanced techniques to further improve model efficiency and accuracy during testing. Stay tuned for our progress on these exciting initiatives.

## Acknowledgments

This work was completed at the [Berkeley Sky Computing Lab](https://sky.cs.berkeley.edu/) with excellent computational support from [Lambda Labs](https://lambdalabs.com/service/gpu-cloud?srsltid=AfmBOop5FnmEFTkavVtdZDsLWvHWNg6peXtat-OXJ9MW5GMNsk756PE5) and [Anyscale](https://www.anyscale.com/). We thank the [Still-2 team](https://arxiv.org/pdf/2412.09413) and Junyang Lin from the [Qwen team](https://qwenlm.github.io/) for valuable academic feedback and support.

## Citation

```bibtex
@misc{sky_t1_2025,
  author       = {NovaSky Team},
  title        = {Sky-T1: Train your own O1 preview model within $450},
  howpublished = {https://novasky-ai.github.io/posts/sky-t1},
  note         = {Accessed: 2025-01-09},
  year         = {2025}
}
```

## ğŸ› ï¸ å®ç”¨å®æ–½æŒ‡å—

### å¿«é€Ÿå…¥é—¨æ•™ç¨‹

#### 1. ç¯å¢ƒè®¾ç½®

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv sky-t1-env
source sky-t1-env/bin/activate  # Linux/Mac
# æˆ–
sky-t1-env\Scripts\activate     # Windows

# å®‰è£…ä¾èµ–é¡¹
pip install torch transformers accelerate
pip install datasets wandb deepspeed
```

#### 2. åŸºæœ¬æ¨¡å‹ä½¿ç”¨

```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
model_name = "NovaSky-AI/Sky-T1-32B-Preview"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map="auto"
)

# æ¨ç†æç¤ºæ¨¡æ¿
def create_reasoning_prompt(problem):
    return f"""é€æ­¥è§£å†³æ­¤é—®é¢˜ï¼Œå±•ç¤ºä½ çš„æ¨ç†è¿‡ç¨‹ï¼š

{problem}

è¯·ä»”ç»†æ€è€ƒå¹¶æä¾›è¯¦ç»†è§£å†³æ–¹æ¡ˆã€‚"""

# ç¤ºä¾‹ç”¨æ³•
problem = "æ‰¾åˆ°æ‰€æœ‰æ­£æ•´æ•° n çš„å’Œï¼Œä½¿å¾— nÂ² + 19n + 88 æ˜¯ä¸€ä¸ªå®Œå…¨å¹³æ–¹æ•°ã€‚"
prompt = create_reasoning_prompt(problem)

inputs = tokenizer(prompt, return_tensors="pt")
with torch.no_grad():
    outputs = model.generate(
        inputs.input_ids,
        max_new_tokens=1000,
        temperature=0.7,
        do_sample=True,
        pad_token_id=tokenizer.eos_token_id
    )

response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### ğŸ”§ é«˜çº§é…ç½®

#### æœ‰é™èµ„æºçš„å†…å­˜ä¼˜åŒ–

```python
from transformers import BitsAndBytesConfig

# 8-bit é‡åŒ–
quantization_config = BitsAndBytesConfig(
    load_in_8bit=True,
    llm_int8_threshold=6.0,
    llm_int8_has_fp16_weight=False,
)

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=quantization_config,
    device_map="auto"
)

# 4-bit é‡åŒ–ï¼ˆå†…å­˜æ•ˆç‡æ›´é«˜ï¼‰
quantization_config_4bit = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4"
)
```

#### ç”¨äºæ•ˆç‡çš„æ‰¹å¤„ç†

```python
def solve_problems_batch(problems, batch_size=4):
    """é«˜æ•ˆå¤„ç†å¤šä¸ªé—®é¢˜"""
    results = []

    for i in range(0, len(problems), batch_size):
        batch = problems[i:i+batch_size]
        prompts = [create_reasoning_prompt(p) for p in batch]

        inputs = tokenizer(prompts, return_tensors="pt", padding=True)

        with torch.no_grad():
            outputs = model.generate(
                inputs.input_ids,
                max_new_tokens=800,
                temperature=0.7,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id
            )

        for j, output in enumerate(outputs):
            response = tokenizer.decode(output, skip_special_tokens=True)
            results.append({
                'problem': batch[j],
                'solution': response,
                'index': i + j
            })

    return results
```

### ğŸ“Š æ€§èƒ½ç›‘æ§

```python
import time
import psutil
import torch

class PerformanceMonitor:
    def __init__(self):
        self.start_time = None
        self.tokens_generated = 0

    def start_monitoring(self):
        self.start_time = time.time()
        torch.cuda.reset_peak_memory_stats()

    def log_metrics(self, num_tokens):
        if self.start_time is None:
            return

        elapsed_time = time.time() - self.start_time
        self.tokens_generated += num_tokens

        # æ€§èƒ½æŒ‡æ ‡
        tokens_per_second = self.tokens_generated / elapsed_time
        gpu_memory = torch.cuda.max_memory_allocated() / 1024**3  # GB
        cpu_percent = psutil.cpu_percent()

        print(f"æ€§èƒ½æŒ‡æ ‡ï¼š")
        print(f"  Tokens/ç§’ï¼š{tokens_per_second:.2f}")
        print(f"  GPU å†…å­˜ï¼š{gpu_memory:.2f} GB")
        print(f"  CPU ä½¿ç”¨ç‡ï¼š{cpu_percent:.1f}%")
        print(f"  æ€» Tokensï¼š{self.tokens_generated}")

# ä½¿ç”¨ç¤ºä¾‹
monitor = PerformanceMonitor()
monitor.start_monitoring()

# ä½ çš„æ¨ç†ä»£ç åœ¨è¿™é‡Œ
response = model.generate(...)

monitor.log_metrics(len(response[0]))
```

---

*æœ‰å…³æ›´è¯¦ç»†çš„ç¤ºä¾‹å’Œé«˜çº§ç”¨æ³•ï¼Œè¯·è®¿é—®æˆ‘ä»¬çš„ [GitHub ä»“åº“](https://github.com/NovaSky-AI/SkyThought)ã€‚*
